{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Annotation Plan**\n",
    "\n",
    "### Annotation Type\n",
    "\n",
    "We will be doing two kinds of annotation: grammatical error correction and error classification. After scraping sentences from Lang-8, most sentences will have corrections. The corrections are the same sentence with grammatical errors fixed by another Lang-8 user. There is no guarantee that the corrections made are appropriate, and that the corrected sentence is indeed grammatical. Therefore, the corrections provided by the Lang-8 community will need to be verified. This verification will be our annotation task. For this task, we will use Mechanical Turk, so our annotators will be Mechanical Turk workers. The question will be “\"Does the Corrected Sentence below correct all of the grammatical errors in the Original sentence? Please select “Yes” or “No”. The task page will look like this: \n",
    "\n",
    "![MT example task](MT_task.png)\n",
    "\n",
    "Given that the only options for this task are “Yes” and “No”, this task is perfect for inter-annotator agreement. Regardless of the annotator, if two annotators decide that the corrected sentence corrects all of the grammatical errors, they will both select “Yes” and that will be the annotation. This would not be the case with free text, and hence we did not include an option to correct the sentence if it is not grammatical.\n",
    "\n",
    "For the second kind of annotations, we will be doing grammatical error classification (time permitting). We will annotate each ungrammatical sentence with the types of errors present in that sentence. We will do this by running the original and corrected sentence pairs that we obtain from the first step through ERRANT. This will give us a machine-determined grammatical error classification. \n",
    "\n",
    "### The amount of annotations\n",
    "\n",
    "We will pay annotators 3 cents per sentence, including the ones used in the pilot study. Each sentence will be annotated using 3 annotators, and we will take the majority (2 out of 3) consensus. This will ensure the quality of the verifications.\n",
    "\n",
    "We used 11 sentences for the pilot study, which cost us \\\\$0.44, since for each sentence, we also pay 1 cent to Amazon. Seeing that we have \\\\$50 to use for Mechanical Turk, this gives us \\\\$49.56 for the remainder of the sentences. We will have 3 annotators per sentence, so that makes 4956 / 3 / 4 = 413 sentences that can be annotated by MT workers. \n",
    "\n",
    "We will be keeping all sentences, regardless of whether MT workers deemed it to be a valid correction or not. For the sentences that were voted “No”, we will tag that sentence pair with “correction invalid”, and for the sentences that were voted “Yes”, we will tag that sentence pair with “correction valid”. So once the annotations are complete, we will have a gold standard set of sentence pairs with verified corrections. The rest of the corpus will still have corrections scraped from Lang-8, but they will not be verified.\n",
    "\n",
    "### Quality of Annotations\n",
    "\n",
    "We have restricted the tasks to workers with a hit approval rate of 95 percent or more. Also, we have restricted the location of workers to the United States to access a large pool of workers whose native language is English. We also increased the payment from 1 cent to 3 cents per task in the hope of obtaining better quality work. \n",
    "\n",
    "### Results of pilot study\n",
    "\n",
    "We conducted a pilot study to ensure that the annotations were what we expected and the instructions were clear. We got 11 workers to annotate 11 sentences, 1 annotator per sentence.\n",
    "\n",
    "Here are the results:\n",
    "\n",
    "![Pilot study results](Pilot_study_results.png \"Results of pilot study\")\n",
    "\n",
    "The results are as we expect. The answers are reasonable, with most sentences being deemed correct, and the one obviously incorrect correction being marked as invalid -  “My mother told me that she doesn’t need to buy one, because, first of all, she likes **to doing** washes.”.  The only difference between the pilot study and the real task will be the multiple annotators per sentence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
