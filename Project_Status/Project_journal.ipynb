{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Status** Feb 22, 2021 \n",
    "\n",
    "1. Darya to complete the first draft of the team contract\n",
    "2. Jeremy created Github\n",
    "3. Christina created Deepnote\n",
    "4. Ali created Wiki for the project\n",
    "5. Shared some ideas of the project: English grammar mistake corpus, Craigslist Job Posting corpus (with skillsets), Coronavirus News corpus\n",
    "6. Everyone to brainstorm on the potential project ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions asked**\n",
    "\n",
    "1. No need to use database to store corpus \n",
    "2. This project does not require machine learning component. (Either hand-annotations or improving upon annotations from pre-trained models)\n",
    "3. The general rule is that if a website is publicly accessible, it is likely to be legal to download anything on it for personal use. It may be illegal if you try to redistribute the data publicly, but for our limited use in this course, this won't be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feb 23, 2021**\n",
    "\n",
    "- met with Jungyeul. To meet with him again on Thursday / Friday 1:30 p.m. PST.\n",
    "\n",
    "\n",
    "1. Darya and Christina to be in charge of Project Proposal (Darya - lead)\n",
    "2. Jeremy and Ali to be in charge of POC (Jeremy - lead)\n",
    "3. Everyone to review the team contract and suggest for modification / improvement\n",
    "4. Everone to check out BEA website\n",
    "5. Everyone to meet and discuss what our (final) corpus will look like after looking at BEA website: meet again on Thursday. \n",
    "6. Everyone to add reference material to the github for tracking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feb 24, 2021**\n",
    "\n",
    "- had a team meeting to discuss 1, 2, 3, 4, 5 from Feb 23.\n",
    "\n",
    "1. Project proposal and team contract almost complete - Darya to finalize the documents.\n",
    "2. Jeremy and Christina installed the Errant and played with it. Jeremy explained to the team and uploaded relevant papers to the repository. \n",
    "3. Discussion about how to scrape enough data from the web - to investigate further.\n",
    "4. Jeremy to write the code and complete POC.\n",
    "5. Met with JY. \n",
    "\n",
    "**Questions asked and answered**\n",
    "\n",
    "1. Our understanding of the project is that a) we collect the original English sentences (written by ESL learners) and the correct English sentences and the corresponding grammar error tags (following ERRANT format) and put into one collection. Is this correct understanding of our contribution? (is classifying the error without providing additional corrections enough of a contribution?)\n",
    "2. How do we store the corpus? (JSON file? CSV file? text file? Do we put it on GitHub?)\n",
    "3. How can we ensure that we have enough data? (Lang-8 suspended - seems to provide a few hundred pages of corrections where each page contains 3 - 8 sentences.)\n",
    "\n",
    "**answers from JY** \n",
    "1. correct. \n",
    "2. txt \n",
    "3. Generally, 20K documents (with 20 sentences) for 1M words are required.  Can you download the current data? even if there are only a few hundreds, and show me how it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feb 27, 2021**\n",
    "\n",
    "1. Milestone 1 completed.\n",
    "2. Darya and Christina worked on Project proposal and Team Contract. Darya was the lead.\n",
    "3. Jeremy and Ali worked on PoC (writing code for scraping and tests). Jeremy was the lead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 1, 2021**\n",
    "\n",
    "Milestone 2 is divided into five parts:\n",
    "\n",
    "1. Complete scraping - Jeremy + Ali\n",
    "2. Corpus + explanation - Jeremy + Ali\n",
    "3. Annotation Plan - Darya + Christina\n",
    "4. Annotation materials - Darya + Christina\n",
    "5. Corpus analysis (Optional) - to discuss on Thursday\n",
    "\n",
    "Jeremy and Ali's Part: \n",
    "\n",
    "1. Test multipage scraping\n",
    "2. Function documentation -> helper.ipynb\n",
    "3. Include multiple language learners(check journal language, only include docs which written in English) -> helper.ipynb\n",
    "4. Write code to remove duplicates(check with JY, word coverage 90%?)\n",
    "5. Synchronization for scraping parallel sents\n",
    "6. Count total number of words\n",
    "\n",
    "Questions for JY:\n",
    "1. Check our understanding of annotation process with JY.\n",
    "2. Can we spend $50 USD on someone who is willing to do the annotation work for us? (instead of using Amazon Mechanical Turks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 2, 2021**\n",
    "\n",
    "Mentor meeting Questions:\n",
    "    \n",
    "1. We plan to scrape both the original sentence (with grammatical errors) and the corrected sentence from the webpage. In this case, do we still need to get annotators? Which of the following options would you recommend?\n",
    "\n",
    "a) no need to get further annotations.\n",
    "    \n",
    "b) only annotate the sentences that do not have corrections.\n",
    "    \n",
    "c) Ignore corrected sentences from the webpage and get annotations from AMT.\n",
    "    \n",
    "d) Ignore corrected sentences from the webpage and get annotations from a hired helper.\n",
    "    \n",
    "e) Get corrected sentences from the webpage and have these corrections verified from workers in AMT.\n",
    "    \n",
    "f) Get corrected sentences from the webpage and have these corrections verified by a hired helper.\n",
    "    \n",
    "2. Can we use $50 USD to hire a helper (instead of spending it on AMT workers?)?\n",
    "3. Development question from Jeremy and Ali: how to remove duplicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentor meeting Answers from JY:\n",
    "    \n",
    "1. I prefer b. \n",
    "2. I guess AMT is something you should do for this class. \n",
    "3. keep duplicates if their corrections are “different” otherwise discard all duplicates except for one example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The group decided to use AMT to verify the grammar corrections in the corrected sentences.\n",
    "- JY asked us to find out the number of sentences we scraped and the number of sentences that overlap with 2019 corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 3, 2021**\n",
    "\n",
    "1. Attempted the GATE annotation work in 523 class. Jeremy submitted the work to Julian. \n",
    "2. Darya to work on documentation and Christina to work on AMT portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 4 and 5, 2021**\n",
    "\n",
    "1. JY messaged that he was not available to meet except 10:30 a.m. PST so we could not meet him.\n",
    "2. Attended Julian's OH. Received some feedback: \n",
    "\n",
    "  - the following would be good options for the inter-annotator agreement task:\n",
    "    - Asking MT workers to select \"Yes\" or \"No\" for whether the corrected sentence is a good correction or not. (pilot study set up this way)\n",
    "    - Selecting the error type present in the original sentence from a list of options. (seems a little complicated, but the output of Errant can be used for this)\n",
    "    - Choosing the best correction amongst duplicate corrections for the same sentence. (the best one probably)\n",
    "    \n",
    "    \n",
    "    Note: Julian said that setting up a MT task is only worth it if we have enough data to get significant work done. For example, for 1, if the turkers will select \"Yes\" more than 80% of the time, that's a waste of our money. \n",
    "    \n",
    "    The team had a discussion and decided to go with: Asking MT workers to select \"Yes\" or \"No\" for whether the corrected sentence is a good correction or not. \n",
    "    \n",
    "3. JY provided some feedback: \n",
    "\n",
    "    - After getting the results from MT, do not discard \"No\" sentences - make a note that the correction is bad, but keep it in the dataset, as this is still interesting and useful data.\n",
    "    - Duplicates - keep them the way we have them. In machine translation, in parallel corpora if the original sentence is the same but translation is different, this is considered a different pair. With the annotations we get, we can tag these pairs with \"correction is good\" or \"correction is bad\".\n",
    "    - Everything we do with Errant is extra - technically, anyone that gets our corpus of parallel sentences can run it through Errant. So for the purposes of this class, we don't have to do it, but we can if we want.  It will be enough to just have the corpus from Lang-8 partially annotated with \"correction is good\" and \"correction is bad\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 8, 2021**\n",
    "\n",
    "1. Milestone 3: \n",
    "\n",
    "- Annotation - Christina and Darya\n",
    "- Interannotator Agreement Study - Darya and Christina\n",
    "- Interface Plan - Jeremy and Ali\n",
    "- Errant Related Work - Jeremy and Ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 9, 2021**\n",
    "\n",
    "1. Web interface and visualization - up to the team. (no specific recommendations from JY) \n",
    "2. JY wants to know the overlap with 2019 Lang-8. \n",
    "3. Jeremy to figure out the overlap.\n",
    "4. Discussion on the front-end and the back-end implementation (Ali, Jeremy and Darya)\n",
    "5. JY to increase the grade to A+ from A\n",
    "6. Search functionality in interface - can search by keyword in sentence\n",
    "7. Front-end logic: can define functions in the front-end, don't have to define everything in the back end\n",
    "8. Sentences: check for and remove exact duplicates (Jeremy to remove duplicates)\n",
    "9. 550 annotations is fine\n",
    "\n",
    "(Point 6 - 9 from Darya: Many thanks!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 11, 2021**\n",
    "\n",
    "0. Thursday meeting time moved to 7:30 a.m. PST instead of 8 a.m. PST.\n",
    "1. annotation work 99% done (seven sentences missing)\n",
    "2. Christina to finish partial corpus (which does not include 2019 overlap)\n",
    "3. Darya to finish interannotator agreement study\n",
    "4. Jeremy to finish the entire corpus (merge 2 with 2019 overlap)\n",
    "5. will not include Errant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistics\n",
    "- Change meeting time to 7:30 am PST on Thursdays from now on (as per Ali's request)- \n",
    "- Mechanical Turk update from Christina:\n",
    "  1643/1650 sentences completed - will make the deadline end of classes today\n",
    "- Visualization ideas for interface\n",
    "- pie chart for valid/invalid sentences\n",
    "- most frequent words excluding stopwords\n",
    "- Jeremy: hard to use ERRANT result -> not going to use ERRANT (it'll take time and it's extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**March 13, 2021** \n",
    "\n",
    "- Darya found that one annotator gave unreliable annotations.\n",
    "- Julians's response: \n",
    "\n",
    "Yes, that's pretty bad, and, yes, you will lose some points. Assuming you've already done the full batch, you have two options to help ameliorate the situation:\n",
    "Look to see if you can use statistical methods to identify bad annotators that you can reject (e.g. Annotators that consistently disagree with others). After you reject, you should be able to redo those annotations (AMT has an option for this, I believe)\n",
    "Do a detailed investigation of what went wrong, and suggest concrete improvements to a hypothetical future round of annotation. This needs to be more than just listing possible solutions, you need to convince us that they would work in this case by making the connection with specific cases of disagreement and/or general statistics.\n",
    "\n",
    "- did not go back to Mechanical turk for re-annotation because the deadline for rejecting work already passed.\n",
    "- we still need to annotate again for the final presentation.\n",
    "\n",
    "\n",
    "**March 15, 2021**\n",
    "- did not meet because of 531 Lab 3 deadline.\n",
    "- moved the team meeting to March 16, 2021 instead. \n",
    "\n",
    "**March 16, 2021** \n",
    " Division of work \n",
    "- Ali - Front End\n",
    "- Jeremy and Christina - Back End\n",
    "- Darya and Christina - Documentation and Dockerization\n",
    "  (Christina less available on Saturday / Sunday)\n",
    "- postponed the mentor meeting to Wednesday\n",
    "\n",
    "**March 17, 2021**\n",
    " Summary from mentor meeting\n",
    "\n",
    "- Our project will be partially graded by our classmates (10%).\n",
    "- To meet with JY on Friday 8 a.m. PST.\n",
    "- Will try to show some visualization to JY on Friday\n",
    "- Visualizations: will need to visualize metadata, graphs are nice for peer evaluation so try to have something fancy (moving, 3D, wordcloud, piechart) can have push-button statistics\n",
    "- will need to have search functionality and be able to explore the corpus through the metadata, sentence by sentence (or just show the entire corpus)\n",
    "- Ali's interface plan looks great!\n",
    "\n",
    "**March 19, 2021**\n",
    "- front end almost done - looks really nice\n",
    "- back end also almost done\n",
    "- front end and back end working together\n",
    "- dockerization successful\n",
    "- more work on front end to make minor corrections \n",
    "\n",
    "**March 20, 2021**\n",
    "- Darya's brother offered help to replace the bad annotator\n",
    "- rebuilt the final corpus with the new annotation: interannotator agreement improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
