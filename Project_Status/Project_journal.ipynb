{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Status** Feb 22, 2021 \n",
    "\n",
    "1. Darya to complete the first draft of the team contract\n",
    "2. Jeremy created Github\n",
    "3. Christina created Deepnote\n",
    "4. Ali created Wiki for the project\n",
    "5. Shared some ideas of the project: English grammar mistake corpus, Craigslist Job Posting corpus (with skillsets), Coronavirus News corpus\n",
    "6. Everyone to brainstorm on the potential project ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions asked**\n",
    "\n",
    "1. No need to use database to store corpus \n",
    "2. This project does not require machine learning component. (Either hand-annotations or improving upon annotations from pre-trained models)\n",
    "3. The general rule is that if a website is publicly accessible, it is likely to be legal to download anything on it for personal use. It may be illegal if you try to redistribute the data publicly, but for our limited use in this course, this won't be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feb 23, 2021**\n",
    "\n",
    "- met with Jungyeul. To meet with him again on Thursday / Friday 1:30 p.m. PST.\n",
    "\n",
    "\n",
    "1. Darya and Christina to be in charge of Project Proposal (Darya - lead)\n",
    "2. Jeremy and Ali to be in charge of POC (Jeremy - lead)\n",
    "3. Everyone to review the team contract and suggest for modification / improvement\n",
    "4. Everone to check out BEA website\n",
    "5. Everyone to meet and discuss what our (final) corpus will look like after looking at BEA website: meet again on Thursday. \n",
    "6. Everyone to add reference material to the github for tracking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feb 24, 2021**\n",
    "\n",
    "- had a team meeting to discuss 1, 2, 3, 4, 5 from Feb 23.\n",
    "\n",
    "1. Project proposal and team contract almost complete - Darya to finalize the documents.\n",
    "2. Jeremy and Christina installed the Errant and played with it. Jeremy explained to the team and uploaded relevant papers to the repository. \n",
    "3. Discussion about how to scrape enough data from the web - to investigate further.\n",
    "4. Jeremy to write the code and complete POC.\n",
    "5. Met with JY. \n",
    "\n",
    "**Questions asked and answered**\n",
    "\n",
    "1. Our understanding of the project is that a) we collect the original English sentences (written by ESL learners) and the correct English sentences and the corresponding grammar error tags (following ERRANT format) and put into one collection. Is this correct understanding of our contribution? (is classifying the error without providing additional corrections enough of a contribution?)\n",
    "2. How do we store the corpus? (JSON file? CSV file? text file? Do we put it on GitHub?)\n",
    "3. How can we ensure that we have enough data? (Lang-8 suspended - seems to provide a few hundred pages of corrections where each page contains 3 - 8 sentences.)\n",
    "\n",
    "**answers from JY** \n",
    "1. correct. \n",
    "2. txt \n",
    "3. Generally, 20K documents (with 20 sentences) for 1M words are required.  Can you download the current data? even if there are only a few hundreds, and show me how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
